<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Structured Bayesian Meta-Learning for Data-Efficient Visual-Tactile Model Estimation">
  <meta name="keywords" content="Tactile sensing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Structured Bayesian Meta-Learning for Data-Efficient Visual-Tactile Model Estimation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://shaoxiongyao.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://motion.cs.illinois.edu/">
            IML UIUC
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Structured Bayesian Meta-Learning for Data-Efficient Visual-Tactile Model Estimation</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Shaoxiong Yao<sup>1</sup>,</span>
            <span class="author-block">Yifan Zhu<sup>2</sup>,</span>
            <span class="author-block">Kris Hauser<sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois at Urbana-Champaign, IL, USA.</span>
            <span class="author-block"><sup>2</sup>Yale University, CT, USA.</span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=TzqKmIhcwq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>OpenReview</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2409.17389"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (Coming soom)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming soom)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser" style="width: 40%; margin: 0 auto;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="media-content">
        <figure class="image">
          <img src="./static/images/star_figure.png" alt="Method overview">
          <figcaption class="subtitle has-text-centered">
            We enable data-efficient visual-tactile model estimation by learning visual-tactile model prior             
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section> -->

<!-- <section class="section" style="width: 100%; margin: 0 auto;"> -->
<section class="hero">
  <div class="container is-max-desktop">
    <!-- TL;DR. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-5">TL;DR: We enable data-efficient visual-tactile model estimation by learning a prior of visual-tactile model from diverse real world objects.</h2>
      </div>
    </div>
    <!--/ TL;DR. -->

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <h2 class="title is-3 has-text-centered">Offline visual-tactile dataset collection</h2>
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/offline_visual_tactile_dataset.mp4"
                    type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Here we show the robot touching several artificial plants. 
            We collect RGBD video streams and corresponding joint torque sensor readings.
          </h2>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <h2 class="title is-3 has-text-centered">Zero-shot prediction from vision</h2>
          <img src="./static/images/large_orange_tree_zero_shot.png" alt="Zero-shot prediction" width="100%">
          <h2 class="subtitle has-text-centered">
            Given a novel object, we use the prior learned offline to predict stiffness from appearance alone. Here, the branch region is predicted to be stiffer than the leaf region, aligning with our intuition. 
          </h2>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <h2 class="title is-3 has-text-centered">Few-shot adaption using touch</h2>
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/large_orange_tree_few_shot.mp4"
                    type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            Once the robot begins touching the plant, we enable efficient stiffness map update using touch data.  Branches behind the leaves cause a torque response larger than expected, leading to an increased estimated stiffness to match observations.
          </h2>
        </div>
      </div>
    </section>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Estimating visual-tactile models of deformable objects is challenging because vision suffers from occlusion while touch data is sparse and noisy.  We propose a novel data-efficient method for dense heterogeneous model estimation by leveraging experience from diverse training objects.  The method is based on Bayesian meta-learning (BML), which can mitigate overfitting high-capacity visual-tactile models by meta-learning an informed prior and naturally achieves few-shot online estimation via posterior estimation.  However, BML requires a shared parametric model across tasks but visual-tactile models for diverse objects have different parameter spaces.  To address this issue, this paper introduces Structured Bayesian Meta-Learning (SBML) that incorporates heterogeneous physics models, enabling learning from training objects with varying appearances and geometries.  SBML performs zero-shot vision-only prediction of deformable model parameters, as well as few-shot adaptation after a handful of touches.  Experiments show that in two classes of heterogeneous objects, namely plants and shoes, SBML outperforms existing approaches in force and torque prediction accuracy in zero- and few-shot settings. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method. -->
    <div class="columns is-centered has-text-centered" style="width: 100%; margin: 0 auto; justify-content: center;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="media-content">
          <figure class="image">
            <img src="./static/images/method_overview_wide.png" alt="Method overview">
            <figcaption class="subtitle has-text-centered">
              An overview of the structured Bayesian meta-learning method. The method learns a high-capacity prior over visual-tactile models from diverse training objects and adapts to novel objects with few touches.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
    <!--/ Method. -->

    <!-- Results. -->
    <div class="columns is-centered has-text-centered" style="width: 100%; margin: 0 auto; justify-content: center;">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <figure class="media-content">
          <video id="shoes-video" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/zero_shot_and_few_shot_shoes.mp4"
                    type="video/mp4">
          </video>
          <figcaption class="subtitle has-text-centered">
            Here we present zero- and few-shot stiffness estimations for test set shoes.
          </figcaption>
        </figure>
      </div>
    </div>
    <!--/ Results. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h3 class="title is-4 has-text-centered">Unified prior over plants and shoes</h3>
    <div class="content">
      <h4 class="title is-6 has-text-centered">Our method can learn a high-capacity prior across multiple object categories. Here we show the unified prior mean prediction trained using both plant and shoe broad datasets. 
      </h4>        
    </div>

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h4 class="title is-5 has-text-centered">Dracaena</h4>
          <img src="./static/images/plant_cross_category_test_0_dracaena_vert_angle00_vis_pcd.png" alt="Dracaena Visualization" width="100%">
          <video id="hazard-video" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/plant_cross_category_test_0_supp_size_0_mu_view.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <h4 class="title is-5 has-text-centered">Orange tree</h4>
        <img src="./static/images/plant_cross_category_test_1_large_orange_tree_angle00_vis_pcd.png" alt="Dracaena Visualization" width="100%">
        <div class="columns is-centered">
          <div class="column content">
            <video id="fruit-collision-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/plant_cross_category_test_1_supp_size_0_mu_view.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="column">
        <h4 class="title is-5 has-text-centered">Leather boot</h4>
        <img src="./static/images/shoe_cross_category_0_brown_columbia_angle00_vis_pcd.png" alt="Dracaena Visualization" width="100%">
        <div class="columns is-centered">
          <div class="column content">
            <video id="leaf-damage-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shoe_cross_category_0_supp_size_0_mu_view.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="column">
        <h4 class="title is-5 has-text-centered">Sneaker</h4>
        <img src="./static/images/shoe_cross_category_1_gray_swiss_shoe_angle00_vis_pcd.png" alt="Dracaena Visualization" width="100%">
        <div class="columns is-centered">
          <div class="column content">
            <video id="leaf-damage-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shoe_cross_category_1_supp_size_0_mu_view.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>

      <div class="column">
        <h4 class="title is-5 has-text-centered">Running shoe</h4>
        <img src="./static/images/shoe_cross_category_2_white_nike_angle00_vis_pcd.png" alt="Dracaena Visualization" width="100%">
        <div class="columns is-centered">
          <div class="column content">
            <video id="leaf-damage-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/shoe_cross_category_2_supp_size_0_mu_view.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> 

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@inproceedings{
  yao2024structured,
  title={Structured Bayesian Meta-Learning for Data-Efficient Visual-Tactile Model Estimation},
  author={Shaoxiong Yao and Yifan Zhu and Kris Hauser},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024},
  url={https://openreview.net/forum?id=TzqKmIhcwq}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We appreciate the website template from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
